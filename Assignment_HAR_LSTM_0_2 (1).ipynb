{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Assignment_HAR_LSTM_0.2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "00e0D8-e7A2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Libraries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv1ZlW-Z_MLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4p_JWeT_OnF",
        "colab_type": "code",
        "outputId": "bef3b2ac-fe33-4798-e10c-5257bd406970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSxZEwaR7A2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_KfrPSZ7A2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Activities are the class labels\n",
        "# It is a 6 class classification\n",
        "ACTIVITIES = {\n",
        "    0: 'WALKING',\n",
        "    1: 'WALKING_UPSTAIRS',\n",
        "    2: 'WALKING_DOWNSTAIRS',\n",
        "    3: 'SITTING',\n",
        "    4: 'STANDING',\n",
        "    5: 'LAYING',\n",
        "}\n",
        "\n",
        "# Utility function to print the confusion matrix\n",
        "def confusion_matrix(Y_true, Y_pred):\n",
        "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
        "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
        "\n",
        "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DCCZT9v7A2k",
        "colab_type": "text"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3Btkh5N7A2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data directory\n",
        "DATADIR = '/content/drive/My Drive/ProjectHAR/HAR/UCI_HAR_Dataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdgnuDj37A2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Raw data signals\n",
        "# Signals are from Accelerometer and Gyroscope\n",
        "# The signals are in x,y,z directions\n",
        "# Sensor signals are filtered to have only body acceleration\n",
        "# excluding the acceleration due to gravity\n",
        "# Triaxial acceleration from the accelerometer is total acceleration\n",
        "SIGNALS = [\n",
        "    \"body_acc_x\",\n",
        "    \"body_acc_y\",\n",
        "    \"body_acc_z\",\n",
        "    \"body_gyro_x\",\n",
        "    \"body_gyro_y\",\n",
        "    \"body_gyro_z\",\n",
        "    \"total_acc_x\",\n",
        "    \"total_acc_y\",\n",
        "    \"total_acc_z\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4XmOUB_7A2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility function to read the data from csv file\n",
        "def _read_csv(filename):\n",
        "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
        "\n",
        "# Utility function to load the load\n",
        "def load_signals(subset):\n",
        "    signals_data = []\n",
        "\n",
        "    for signal in SIGNALS:\n",
        "        filename = f'/content/drive/My Drive/ProjectHAR/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
        "        signals_data.append(\n",
        "            _read_csv(filename).as_matrix()\n",
        "        ) \n",
        "\n",
        "    # Transpose is used to change the dimensionality of the output,\n",
        "    #/content/drive/My Drive/HumanActivityRecognition.zip (Unzipped Files)/HAR/UCI_HAR_Dataset/train/subject_train.txt\n",
        "    #/content/drive/My Drive/HumanActivityRecognition.zip (Unzipped Files) (1)/HAR/UCI_HAR_Dataset/test/Inertial Signals/body_acc_x_test.txt\n",
        "    # aggregating the signals by combination of sample/timestep.\n",
        "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
        "    return np.transpose(signals_data, (1, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DazjcjK37A22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_y(subset):\n",
        "    \"\"\"\n",
        "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
        "    that represents a human activity. We return a binary representation of \n",
        "    every sample objective as a 6 bits vector using One Hot Encoding\n",
        "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
        "    \"\"\"\n",
        "    filename = f'/content/drive/My Drive/ProjectHAR/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
        "    y = _read_csv(filename)[0]\n",
        "\n",
        "    return pd.get_dummies(y).as_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z5DXqDC7A28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    \n",
        "    X_train, X_test = load_signals('train'), load_signals('test')\n",
        "    y_train, y_test = load_y('train'), load_y('test')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EJonkim7A3C",
        "colab_type": "code",
        "outputId": "74a2dbbf-0d46-4b5f-9256-945ef7214861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "# Importing tensorflow\n",
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri5b1e7D7A3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configuring a session\n",
        "session_conf = tf.ConfigProto(\n",
        "    intra_op_parallelism_threads=1,\n",
        "    inter_op_parallelism_threads=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOEJVJXY7A3N",
        "colab_type": "code",
        "outputId": "c6b19362-4dd1-4c23-feb6-1605c453a29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import Keras\n",
        "from keras import backend as K\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT6EDTJ17A3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqxt2ntG7A3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing parameters\n",
        "epochs = 30\n",
        "batch_size = 16\n",
        "n_hidden = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr1ztvxP7A3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility function to count the number of classes\n",
        "def _count_classes(y):\n",
        "    return len(set([tuple(category) for category in y]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGLKVDFF7A3l",
        "colab_type": "code",
        "outputId": "4fb03eda-cce6-4dbe-a894-a09e6aeffd55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Loading the train and test data\n",
        "X_train, X_test, Y_train, Y_test = load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jytqUM1A7A3q",
        "colab_type": "code",
        "outputId": "a40fc936-87f5-4b20-f0e3-f4e67ff62381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "timesteps = len(X_train[0])\n",
        "input_dim = len(X_train[0][0])\n",
        "n_classes = _count_classes(Y_train)\n",
        "\n",
        "print(timesteps)\n",
        "print(input_dim)\n",
        "print(len(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "9\n",
            "7352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa58IiDXX3hP",
        "colab_type": "code",
        "outputId": "277c7fc8-ce9f-4708-edef-9f54271e5a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7352, 128, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw50faRskdR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing parameters\n",
        "epochs = 30\n",
        "batch_size = 16\n",
        "n_hidden = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SOQJG757A3y",
        "colab_type": "text"
      },
      "source": [
        "## **LSTM Architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTyvdtv153pg",
        "colab_type": "text"
      },
      "source": [
        "## **1-Layer LSTM with 32 units**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX_Eq4-57A30",
        "colab_type": "code",
        "outputId": "3d171130-92d3-4c1e-9625-ef901d1c022f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "# Initiliazing the sequential model\n",
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 32)                5376      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 5,574\n",
            "Trainable params: 5,574\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6c1TxiL7A3_",
        "colab_type": "code",
        "outputId": "abf974f7-dc44-4636-de9c-d321aa50331c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcreA4sE7A4D",
        "colab_type": "code",
        "outputId": "eb6d4857-8f0f-4ffc-e9dc-004d837d7737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training the model\n",
        "model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=batch_size,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "7352/7352 [==============================] - 33s 5ms/step - loss: 1.3108 - acc: 0.4396 - val_loss: 1.1289 - val_acc: 0.4774\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.9592 - acc: 0.5887 - val_loss: 0.8989 - val_acc: 0.5860\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.8008 - acc: 0.6419 - val_loss: 0.8027 - val_acc: 0.5911\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.6974 - acc: 0.6533 - val_loss: 0.8914 - val_acc: 0.5816\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.6501 - acc: 0.6740 - val_loss: 0.7635 - val_acc: 0.6077\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.5935 - acc: 0.6910 - val_loss: 0.7337 - val_acc: 0.6661\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.5612 - acc: 0.7228 - val_loss: 0.6725 - val_acc: 0.7085\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.5526 - acc: 0.7486 - val_loss: 0.6597 - val_acc: 0.7418\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.7021 - acc: 0.7042 - val_loss: 0.8901 - val_acc: 0.7078\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.4976 - acc: 0.7972 - val_loss: 0.5938 - val_acc: 0.7346\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.4290 - acc: 0.8150 - val_loss: 0.5231 - val_acc: 0.7730\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.4006 - acc: 0.8349 - val_loss: 0.5778 - val_acc: 0.8392\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.3410 - acc: 0.8919 - val_loss: 0.4934 - val_acc: 0.8707\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.3025 - acc: 0.9199 - val_loss: 0.5637 - val_acc: 0.8409\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.2880 - acc: 0.9212 - val_loss: 0.5171 - val_acc: 0.8748\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.2427 - acc: 0.9257 - val_loss: 0.4294 - val_acc: 0.8823\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.2419 - acc: 0.9310 - val_loss: 0.4707 - val_acc: 0.8856\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.2035 - acc: 0.9387 - val_loss: 0.4186 - val_acc: 0.8918\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.2081 - acc: 0.9387 - val_loss: 0.5346 - val_acc: 0.8694\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1823 - acc: 0.9442 - val_loss: 0.6114 - val_acc: 0.8741\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1984 - acc: 0.9385 - val_loss: 0.4389 - val_acc: 0.8897\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1895 - acc: 0.9446 - val_loss: 0.5074 - val_acc: 0.8958\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.2099 - acc: 0.9373 - val_loss: 0.5030 - val_acc: 0.8955\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.2058 - acc: 0.9380 - val_loss: 0.6214 - val_acc: 0.8975\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1969 - acc: 0.9408 - val_loss: 0.9202 - val_acc: 0.8534\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.2420 - acc: 0.9331 - val_loss: 0.5706 - val_acc: 0.8904\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1571 - acc: 0.9455 - val_loss: 0.6182 - val_acc: 0.8836\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1663 - acc: 0.9437 - val_loss: 0.4404 - val_acc: 0.9053\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1736 - acc: 0.9425 - val_loss: 0.4823 - val_acc: 0.8880\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1525 - acc: 0.9487 - val_loss: 0.4853 - val_acc: 0.8894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f367684b860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2-F7EnDDRMV",
        "colab_type": "code",
        "outputId": "efe7f097-c1ff-4e2b-f7a0-7bd4e4b91888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 32)                5376      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 5,574\n",
            "Trainable params: 5,574\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEkvo1YI7A4L",
        "colab_type": "code",
        "outputId": "24950dae-f74a-4be6-e22d-112e723e961a",
        "colab": {}
      },
      "source": [
        "# Confusion Matrix\n",
        "print(confusion_matrix(Y_test, model.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
            "True                                                                         \n",
            "LAYING                 512        0        25        0                   0   \n",
            "SITTING                  3      410        75        0                   0   \n",
            "STANDING                 0       87       445        0                   0   \n",
            "WALKING                  0        0         0      481                   2   \n",
            "WALKING_DOWNSTAIRS       0        0         0        0                 382   \n",
            "WALKING_UPSTAIRS         0        0         0        2                  18   \n",
            "\n",
            "Pred                WALKING_UPSTAIRS  \n",
            "True                                  \n",
            "LAYING                             0  \n",
            "SITTING                            3  \n",
            "STANDING                           0  \n",
            "WALKING                           13  \n",
            "WALKING_DOWNSTAIRS                38  \n",
            "WALKING_UPSTAIRS                 451  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YgmTp7I7A4W",
        "colab_type": "code",
        "outputId": "665a3411-dd56-4d4b-b772-585e326c7b0b",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2947/2947 [==============================] - 4s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5yvpqG87A4c",
        "colab_type": "code",
        "outputId": "9c47c4cd-a9e8-46de-b1d5-b22fd31a5a9a",
        "colab": {}
      },
      "source": [
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3087582236972612, 0.9097387173396675]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz2iMvtnJv6-",
        "colab_type": "text"
      },
      "source": [
        "Here the test accuracy is 91%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgvVfuiO6NzJ",
        "colab_type": "text"
      },
      "source": [
        "## **1-Layer LSTM with 128 units**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2tJhzqo0ACT",
        "colab_type": "code",
        "outputId": "8a9ef4d2-118d-476b-a234-22b3c070306d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Importing libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Dropout\n",
        "# Initiliazing the sequential model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128,return_sequences=True,input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.7))\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(128, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.8))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 128, 128)          70656     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 203,014\n",
            "Trainable params: 203,014\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjJwoPW-0C7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1AqBYGs0Gn_",
        "colab_type": "code",
        "outputId": "285ddef0-36ca-46f0-dc41-52edb9469d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "source": [
        "# Training the model\n",
        "model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=batch_size,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/20\n",
            "7352/7352 [==============================] - 142s 19ms/step - loss: 1.4266 - acc: 0.3531 - val_loss: 1.4238 - val_acc: 0.3482\n",
            "Epoch 2/20\n",
            "7352/7352 [==============================] - 138s 19ms/step - loss: 1.3791 - acc: 0.3626 - val_loss: 1.5759 - val_acc: 0.3308\n",
            "Epoch 3/20\n",
            "7352/7352 [==============================] - 138s 19ms/step - loss: 1.4487 - acc: 0.3532 - val_loss: 1.4030 - val_acc: 0.3461\n",
            "Epoch 4/20\n",
            "7352/7352 [==============================] - 139s 19ms/step - loss: 1.3371 - acc: 0.3789 - val_loss: 1.3970 - val_acc: 0.3448\n",
            "Epoch 5/20\n",
            "7352/7352 [==============================] - 139s 19ms/step - loss: 1.2915 - acc: 0.3974 - val_loss: 1.2594 - val_acc: 0.4330\n",
            "Epoch 6/20\n",
            "7352/7352 [==============================] - 139s 19ms/step - loss: 1.2958 - acc: 0.3970 - val_loss: 1.3881 - val_acc: 0.3590\n",
            "Epoch 7/20\n",
            "7352/7352 [==============================] - 139s 19ms/step - loss: 1.0841 - acc: 0.4999 - val_loss: 0.9535 - val_acc: 0.4941\n",
            "Epoch 8/20\n",
            "7352/7352 [==============================] - 139s 19ms/step - loss: 0.9039 - acc: 0.5103 - val_loss: 1.5978 - val_acc: 0.4028\n",
            "Epoch 9/20\n",
            "7352/7352 [==============================] - 139s 19ms/step - loss: 0.9719 - acc: 0.4950 - val_loss: 0.8858 - val_acc: 0.4747\n",
            "Epoch 10/20\n",
            "7352/7352 [==============================] - 139s 19ms/step - loss: 0.8057 - acc: 0.5295 - val_loss: 1.4350 - val_acc: 0.3437\n",
            "Epoch 11/20\n",
            "7352/7352 [==============================] - 138s 19ms/step - loss: 0.8039 - acc: 0.5305 - val_loss: 0.8417 - val_acc: 0.5646\n",
            "Epoch 12/20\n",
            "7352/7352 [==============================] - 139s 19ms/step - loss: 0.7675 - acc: 0.5465 - val_loss: 0.8443 - val_acc: 0.5215\n",
            "Epoch 13/20\n",
            "7352/7352 [==============================] - 138s 19ms/step - loss: 0.7727 - acc: 0.5416 - val_loss: 0.8390 - val_acc: 0.5215\n",
            "Epoch 14/20\n",
            "7352/7352 [==============================] - 138s 19ms/step - loss: 0.7578 - acc: 0.5563 - val_loss: 0.8150 - val_acc: 0.5178\n",
            "Epoch 15/20\n",
            "7352/7352 [==============================] - 138s 19ms/step - loss: 0.7688 - acc: 0.5477 - val_loss: 0.7978 - val_acc: 0.5219\n",
            "Epoch 16/20\n",
            "7352/7352 [==============================] - 138s 19ms/step - loss: 0.7945 - acc: 0.5552 - val_loss: 0.7739 - val_acc: 0.5202\n",
            "Epoch 17/20\n",
            "7352/7352 [==============================] - 138s 19ms/step - loss: 0.7814 - acc: 0.5564 - val_loss: 0.7690 - val_acc: 0.5249\n",
            "Epoch 18/20\n",
            "7352/7352 [==============================] - 138s 19ms/step - loss: 0.7245 - acc: 0.5700 - val_loss: 0.6907 - val_acc: 0.5453\n",
            "Epoch 19/20\n",
            "7352/7352 [==============================] - 136s 19ms/step - loss: 0.7040 - acc: 0.6174 - val_loss: 0.8053 - val_acc: 0.5643\n",
            "Epoch 20/20\n",
            "7352/7352 [==============================] - 136s 18ms/step - loss: 1.1929 - acc: 0.4747 - val_loss: 0.8546 - val_acc: 0.5114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcaca5534e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQJtSrB5XCX2",
        "colab_type": "text"
      },
      "source": [
        "## **HyperParameter tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwJ5lq4DXIXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hyperparameter tuning of number of Lstm units\n",
        "from keras.optimizers import Adam,RMSprop,SGD\n",
        "def best_hyperparameters(hidden):\n",
        "\n",
        "    model = Sequential()\n",
        "    # Configuring the parameters\n",
        "    model.add(LSTM(hidden, input_shape=(timesteps, input_dim)))\n",
        "    # Adding a dropout layer\n",
        "    model.add(Dropout(0.5))\n",
        "    # Adding a dense output layer with sigmoid activation\n",
        "    model.add(Dense(n_classes, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehkIjYOtZBEx",
        "colab_type": "code",
        "outputId": "68bfaab2-fb46-433e-b365-b558dcfb438f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "\n",
        "hidden = [16,32,48,64]\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = KerasClassifier(build_fn=best_hyperparameters, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "param_grid = dict(hidden=hidden)\n",
        "\n",
        "# if you are using CPU\n",
        "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "# if you are using GPU dont use the n_jobs parameter\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-YObOS7aGLO",
        "colab_type": "code",
        "outputId": "569e36b4-a702-457f-c2ad-8f30509a74a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.907916 using {'hidden': 48}\n",
            "0.811752 (0.040857) with: {'hidden': 16}\n",
            "0.904652 (0.022746) with: {'hidden': 32}\n",
            "0.907916 (0.013044) with: {'hidden': 48}\n",
            "0.875544 (0.037676) with: {'hidden': 64}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKHh2GFmpLDX",
        "colab_type": "text"
      },
      "source": [
        "After applying hyperparameter tuning on the number of hidden layers, hidden layers of 48 has the better accuracy of 90.7%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCgEbNaPpzqO",
        "colab_type": "text"
      },
      "source": [
        "## **Hyperparameter tuning of the dropout rates**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZygXznBJkPPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def best_hyperparameters(dp):\n",
        "\n",
        "    model = Sequential()\n",
        "    # Configuring the parameters\n",
        "    model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
        "    # Adding a dropout layer\n",
        "    model.add(Dropout(dp))\n",
        "    # Adding a dense output layer with sigmoid activation\n",
        "    model.add(Dense(n_classes, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='rmsprop')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzqVhyP6kk1X",
        "colab_type": "code",
        "outputId": "27973d0d-8a16-4b64-aa10-4a1adeedbe08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "\n",
        "dp = [0.2,0.3,0.4]\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = KerasClassifier(build_fn=best_hyperparameters, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "param_grid = dict(dp=dp)\n",
        "\n",
        "# if you are using CPU\n",
        "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "# if you are using GPU dont use the n_jobs parameter\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd9YcEPTlLd8",
        "colab_type": "code",
        "outputId": "458ad39a-4c4f-448f-d91f-c133bf13e541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.903292 using {'dp': 0.3}\n",
            "0.867111 (0.059060) with: {'dp': 0.2}\n",
            "0.903292 (0.035037) with: {'dp': 0.3}\n",
            "0.894314 (0.015809) with: {'dp': 0.4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwZtmgHWp9g-",
        "colab_type": "text"
      },
      "source": [
        "The best drop out rate after hyperparametertuning is 0.3 with a accuracy of 90%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzSutwY_GP2F",
        "colab_type": "text"
      },
      "source": [
        "## **2- Layer LSTM with 32 units**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sENWSoFTFtBT",
        "colab_type": "code",
        "outputId": "aeceafea-7d75-4e82-8ddc-ca53897c12ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "epochs = 30\n",
        "batch_size = 16\n",
        "n_hidden = 32 \n",
        "\n",
        "\n",
        "model = Sequential() # Initiliazing the sequential model5\n",
        "model.add(LSTM(n_hidden, return_sequences=True, input_shape=(timesteps, input_dim))) # First LSTM Layer\n",
        "model.add(Dropout(0.5)) # Adding a dropout layer\n",
        "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) # Second LSTM Layer\n",
        "model.add(BatchNormalization()) # Adding batch normalization\n",
        "model.add(Dropout(0.5)) # Adding a dropout layer\n",
        "model.add(Dense(n_classes, activation='sigmoid')) # Adding a dense output layer with sigmoid activation\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 128, 32)           5376      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 14,022\n",
            "Trainable params: 13,958\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVy3MtzjHZo0",
        "colab_type": "code",
        "outputId": "658a20cc-451c-43dd-b700-1f2ed29c8872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) # Compiling the model\n",
        "# Training the model\n",
        "model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=batch_size,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/20\n",
            "7352/7352 [==============================] - 72s 10ms/step - loss: 1.0729 - acc: 0.5250 - val_loss: 0.8262 - val_acc: 0.5836\n",
            "Epoch 2/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.7666 - acc: 0.5944 - val_loss: 0.7741 - val_acc: 0.6186\n",
            "Epoch 3/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.7430 - acc: 0.5835 - val_loss: 0.7442 - val_acc: 0.6040\n",
            "Epoch 4/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.7037 - acc: 0.6213 - val_loss: 0.6824 - val_acc: 0.6261\n",
            "Epoch 5/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.6536 - acc: 0.6530 - val_loss: 0.7131 - val_acc: 0.6118\n",
            "Epoch 6/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.5804 - acc: 0.6692 - val_loss: 1.0870 - val_acc: 0.5847\n",
            "Epoch 7/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.5361 - acc: 0.6730 - val_loss: 0.6608 - val_acc: 0.6254\n",
            "Epoch 8/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.5347 - acc: 0.6835 - val_loss: 0.7658 - val_acc: 0.6233\n",
            "Epoch 9/20\n",
            "7352/7352 [==============================] - 68s 9ms/step - loss: 0.5034 - acc: 0.7021 - val_loss: 0.6991 - val_acc: 0.6278\n",
            "Epoch 10/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.4840 - acc: 0.7334 - val_loss: 0.5849 - val_acc: 0.7652\n",
            "Epoch 11/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.3888 - acc: 0.8003 - val_loss: 0.5745 - val_acc: 0.7659\n",
            "Epoch 12/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.3104 - acc: 0.8531 - val_loss: 0.5133 - val_acc: 0.8928\n",
            "Epoch 13/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.2398 - acc: 0.9234 - val_loss: 0.4791 - val_acc: 0.8928\n",
            "Epoch 14/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.2025 - acc: 0.9336 - val_loss: 0.4292 - val_acc: 0.8985\n",
            "Epoch 15/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1726 - acc: 0.9396 - val_loss: 0.5870 - val_acc: 0.8982\n",
            "Epoch 16/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1867 - acc: 0.9387 - val_loss: 0.5331 - val_acc: 0.9043\n",
            "Epoch 17/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1841 - acc: 0.9359 - val_loss: 0.3835 - val_acc: 0.8941\n",
            "Epoch 18/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1735 - acc: 0.9407 - val_loss: 0.4648 - val_acc: 0.9138\n",
            "Epoch 19/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1930 - acc: 0.9381 - val_loss: 0.5247 - val_acc: 0.9094\n",
            "Epoch 20/20\n",
            "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1696 - acc: 0.9438 - val_loss: 0.6018 - val_acc: 0.8989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0bd9a88e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc_bVZBSICmr",
        "colab_type": "code",
        "outputId": "326e396f-bfe0-4c90-d886-66174c25af20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: nan\n",
            "Test accuracy: 0.168306752629793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsdcYRnAIDoR",
        "colab_type": "text"
      },
      "source": [
        "## **2 Layer LSTM with 64 units**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TERAQgwaIOQT",
        "colab_type": "code",
        "outputId": "b3fda96e-76e7-4894-9cf0-3181dcb6a214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Dropout\n",
        "\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "epochs = 30\n",
        "batch_size = 16\n",
        "n_hidden = 64 \n",
        "\n",
        "model6 = Sequential() # Initiliazing the sequential model6\n",
        "model6.add(LSTM(n_hidden, return_sequences=True, input_shape=(timesteps, input_dim))) # First LSTM Layer\n",
        "model6.add(Dropout(0.5)) # Adding a dropout layer\n",
        "model6.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) # Second LSTM Layer\n",
        "model6.add(BatchNormalization()) # Adding batch normalization\n",
        "model6.add(Dropout(0.5)) # Adding a dropout layer\n",
        "model6.add(Dense(n_classes, activation='sigmoid')) # Adding a dense output layer with sigmoid activation\n",
        "model6.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 128, 64)           18944     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128, 64)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 52,614\n",
            "Trainable params: 52,486\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeXvI7hyI0FQ",
        "colab_type": "code",
        "outputId": "eee87a94-8bb1-4e97-f691-2442aa75af73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model6.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) # Compiling the model\n",
        "# Training the model\n",
        "model6.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=batch_size,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "7352/7352 [==============================] - 77s 11ms/step - loss: 0.9581 - acc: 0.5652 - val_loss: 0.7742 - val_acc: 0.5558\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 75s 10ms/step - loss: 0.7610 - acc: 0.5964 - val_loss: 0.8119 - val_acc: 0.5864\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.7460 - acc: 0.5895 - val_loss: 0.7187 - val_acc: 0.6237\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.6410 - acc: 0.5926 - val_loss: 0.9511 - val_acc: 0.6132\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.5845 - acc: 0.6390 - val_loss: 0.6596 - val_acc: 0.6193\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.5287 - acc: 0.6609 - val_loss: 0.7717 - val_acc: 0.6189\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.4840 - acc: 0.6746 - val_loss: 0.7026 - val_acc: 0.6508\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.4063 - acc: 0.7792 - val_loss: 0.6101 - val_acc: 0.7665\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.2970 - acc: 0.8509 - val_loss: 0.5405 - val_acc: 0.8772\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1889 - acc: 0.9353 - val_loss: 0.7157 - val_acc: 0.8755\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1793 - acc: 0.9377 - val_loss: 0.6498 - val_acc: 0.8958\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1628 - acc: 0.9429 - val_loss: 0.4786 - val_acc: 0.8928\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1525 - acc: 0.9421 - val_loss: 0.5926 - val_acc: 0.9077\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 74s 10ms/step - loss: 0.1474 - acc: 0.9430 - val_loss: 0.3830 - val_acc: 0.9104\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1657 - acc: 0.9446 - val_loss: 0.5756 - val_acc: 0.9026\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 77s 11ms/step - loss: 0.1469 - acc: 0.9460 - val_loss: 0.4715 - val_acc: 0.9216\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1525 - acc: 0.9430 - val_loss: 0.5181 - val_acc: 0.9026\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1523 - acc: 0.9387 - val_loss: 0.8799 - val_acc: 0.8799\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1986 - acc: 0.9421 - val_loss: 0.6696 - val_acc: 0.9121\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1619 - acc: 0.9418 - val_loss: 0.5845 - val_acc: 0.8918\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1423 - acc: 0.9441 - val_loss: 0.7462 - val_acc: 0.8826\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1683 - acc: 0.9463 - val_loss: 0.7275 - val_acc: 0.8856\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1397 - acc: 0.9486 - val_loss: 0.6610 - val_acc: 0.9043\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1483 - acc: 0.9490 - val_loss: 0.5524 - val_acc: 0.9040\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1371 - acc: 0.9482 - val_loss: 0.6212 - val_acc: 0.9125\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 74s 10ms/step - loss: 0.1411 - acc: 0.9470 - val_loss: 0.6626 - val_acc: 0.9067\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1570 - acc: 0.9456 - val_loss: 0.5271 - val_acc: 0.9155\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1505 - acc: 0.9482 - val_loss: 0.7322 - val_acc: 0.8951\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1362 - acc: 0.9490 - val_loss: 0.6192 - val_acc: 0.9125\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1341 - acc: 0.9482 - val_loss: 0.5394 - val_acc: 0.9111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f54bdb20e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0NTkHk1I5CH",
        "colab_type": "code",
        "outputId": "b526572a-830e-41cb-a503-6b18cf60a8f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score = model6.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.5397744755697206\n",
            "Test accuracy: 0.9110960298608755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtgHKjIjb2ne",
        "colab_type": "text"
      },
      "source": [
        "## **2-Layer LSTM with 128 units**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc6KGZmuGDWu",
        "colab_type": "code",
        "outputId": "17d752ae-c37d-4797-c517-a912f9758ba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 30\n",
        "batch_size = 16\n",
        "n_hidden = 128 #64 LSTM Units\n",
        "\n",
        "model7 = Sequential() # Initiliazing the sequential model7\n",
        "model7.add(LSTM(n_hidden, return_sequences=True, input_shape=(timesteps, input_dim))) # First LSTM Layer\n",
        "model7.add(Dropout(0.3)) # Adding a dropout layer\n",
        "model7.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) # Second LSTM Layer\n",
        "model7.add(BatchNormalization()) # Adding batch normalization\n",
        "model7.add(Dropout(0.3)) # Adding a dropout layer\n",
        "model7.add(Dense(n_classes, activation='sigmoid')) # Adding a dense output layer with sigmoid activation\n",
        "model7.summary()\n",
        "model7.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) # Compiling the model\n",
        "model7.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_test, Y_test), epochs=epochs) # Training the model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 128, 128)          70656     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 203,526\n",
            "Trainable params: 203,270\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 135s 18ms/step - loss: 0.9785 - acc: 0.5643 - val_loss: 0.8272 - val_acc: 0.6261\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.7378 - acc: 0.6250 - val_loss: 0.8826 - val_acc: 0.6111\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.7219 - acc: 0.6317 - val_loss: 0.7472 - val_acc: 0.5976\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.6700 - acc: 0.6602 - val_loss: 0.7278 - val_acc: 0.5982\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.5946 - acc: 0.7240 - val_loss: 0.4438 - val_acc: 0.8741\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.2886 - acc: 0.8993 - val_loss: 0.7702 - val_acc: 0.7645\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.2378 - acc: 0.9196 - val_loss: 0.3371 - val_acc: 0.9030\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1785 - acc: 0.9347 - val_loss: 0.4042 - val_acc: 0.8999\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1812 - acc: 0.9336 - val_loss: 0.3650 - val_acc: 0.9019\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1607 - acc: 0.9395 - val_loss: 0.3648 - val_acc: 0.9023\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1512 - acc: 0.9406 - val_loss: 0.4122 - val_acc: 0.8962\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1826 - acc: 0.9387 - val_loss: 0.3982 - val_acc: 0.9060\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1491 - acc: 0.9449 - val_loss: 0.4368 - val_acc: 0.8887\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1483 - acc: 0.9429 - val_loss: 0.3269 - val_acc: 0.9080\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1363 - acc: 0.9444 - val_loss: 0.3985 - val_acc: 0.9053\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1464 - acc: 0.9470 - val_loss: 0.4837 - val_acc: 0.8999\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1612 - acc: 0.9489 - val_loss: 0.2760 - val_acc: 0.9240\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1287 - acc: 0.9516 - val_loss: 0.4119 - val_acc: 0.9077\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1546 - acc: 0.9465 - val_loss: 0.8147 - val_acc: 0.8738\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1429 - acc: 0.9509 - val_loss: 0.4122 - val_acc: 0.9080\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 130s 18ms/step - loss: 0.1543 - acc: 0.9453 - val_loss: 0.3857 - val_acc: 0.9094\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 130s 18ms/step - loss: 0.1390 - acc: 0.9514 - val_loss: 0.3141 - val_acc: 0.9138\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1206 - acc: 0.9478 - val_loss: 0.5881 - val_acc: 0.8897\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1283 - acc: 0.9465 - val_loss: 0.3048 - val_acc: 0.9230\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1473 - acc: 0.9490 - val_loss: 0.2518 - val_acc: 0.9294\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.1414 - acc: 0.9483 - val_loss: 0.4858 - val_acc: 0.8938\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1569 - acc: 0.9452 - val_loss: 0.3868 - val_acc: 0.9230\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1349 - acc: 0.9504 - val_loss: 0.3845 - val_acc: 0.9145\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1502 - acc: 0.9463 - val_loss: 0.3964 - val_acc: 0.9104\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1249 - acc: 0.9518 - val_loss: 0.3855 - val_acc: 0.9006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f54aef76a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQy0AnuJlQTp",
        "colab_type": "code",
        "outputId": "35a3fee2-a16d-46ac-fcfd-37d773f69d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score = model7.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.3855398340146181\n",
            "Test accuracy: 0.9005768578215134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fcU5QYGlPZU",
        "colab_type": "text"
      },
      "source": [
        "Lets increase the dropout rate to 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKME3zGVH1Mf",
        "colab_type": "text"
      },
      "source": [
        "## **2-Layer LSTM with dropout rate=0.5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Gplj8TmT7n",
        "colab_type": "code",
        "outputId": "5da55d1a-2825-4e1f-8814-1c83927af91c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 30\n",
        "batch_size = 16\n",
        "n_hidden = 128 #64 LSTM Units\n",
        "\n",
        "model3 = Sequential() # Initiliazing the sequential model7\n",
        "model3.add(LSTM(n_hidden, return_sequences=True, input_shape=(timesteps, input_dim))) # First LSTM Layer\n",
        "model3.add(Dropout(0.5)) # Adding a dropout layer\n",
        "model3.add(LSTM(n_hidden, input_shape=(timesteps, input_dim))) # Second LSTM Layer\n",
        "model3.add(BatchNormalization()) # Adding batch normalization\n",
        "model3.add(Dropout(0.5)) # Adding a dropout layer\n",
        "model3.add(Dense(n_classes, activation='sigmoid')) # Adding a dense output layer with sigmoid activation\n",
        "model3.summary()\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # Compiling the model\n",
        "model3.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_test, Y_test), epochs=epochs) # Training the model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_5 (LSTM)                (None, 128, 128)          70656     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 203,526\n",
            "Trainable params: 203,270\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 136s 19ms/step - loss: 0.9981 - acc: 0.5513 - val_loss: 0.7959 - val_acc: 0.5355\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.8415 - acc: 0.5350 - val_loss: 0.7847 - val_acc: 0.6121\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.7349 - acc: 0.6084 - val_loss: 0.8644 - val_acc: 0.5185\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.6906 - acc: 0.6364 - val_loss: 0.7108 - val_acc: 0.6230\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 131s 18ms/step - loss: 0.6264 - acc: 0.6438 - val_loss: 0.6724 - val_acc: 0.6539\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.5347 - acc: 0.6733 - val_loss: 0.6468 - val_acc: 0.6563\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 1.1230 - acc: 0.5241 - val_loss: 0.8021 - val_acc: 0.6149\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.8200 - acc: 0.5963 - val_loss: 0.8038 - val_acc: 0.6088\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.6348 - acc: 0.6689 - val_loss: 0.5699 - val_acc: 0.6284\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.5041 - acc: 0.7964 - val_loss: 0.4850 - val_acc: 0.8205\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.2679 - acc: 0.9071 - val_loss: 0.3464 - val_acc: 0.8819\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.2004 - acc: 0.9253 - val_loss: 0.3310 - val_acc: 0.8941\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.2068 - acc: 0.9232 - val_loss: 0.3193 - val_acc: 0.9013\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.1693 - acc: 0.9358 - val_loss: 0.3612 - val_acc: 0.9060\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.1538 - acc: 0.9433 - val_loss: 0.3732 - val_acc: 0.9063\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.1602 - acc: 0.9414 - val_loss: 0.3108 - val_acc: 0.9046\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.1587 - acc: 0.9387 - val_loss: 0.4622 - val_acc: 0.8968\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.1615 - acc: 0.9404 - val_loss: 0.3444 - val_acc: 0.9145\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.1336 - acc: 0.9479 - val_loss: 0.3617 - val_acc: 0.9114\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.1385 - acc: 0.9449 - val_loss: 0.3542 - val_acc: 0.9002\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.1627 - acc: 0.9378 - val_loss: 0.2905 - val_acc: 0.9141\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.1280 - acc: 0.9470 - val_loss: 0.4010 - val_acc: 0.9074\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.1366 - acc: 0.9440 - val_loss: 0.3570 - val_acc: 0.9101\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.1287 - acc: 0.9494 - val_loss: 0.3901 - val_acc: 0.9036\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.1484 - acc: 0.9452 - val_loss: 0.4312 - val_acc: 0.8999\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.2257 - acc: 0.9259 - val_loss: 0.3103 - val_acc: 0.9101\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.1439 - acc: 0.9446 - val_loss: 0.8048 - val_acc: 0.8347\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 132s 18ms/step - loss: 0.1572 - acc: 0.9380 - val_loss: 0.3418 - val_acc: 0.9152\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.1325 - acc: 0.9475 - val_loss: 0.3636 - val_acc: 0.9087\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 133s 18ms/step - loss: 0.1407 - acc: 0.9442 - val_loss: 0.3209 - val_acc: 0.9145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f54ae2c7390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8m99uXa20uI",
        "colab_type": "code",
        "outputId": "a4195386-07ad-4add-e525-156b31e4a312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score = model3.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.3208585181328503\n",
            "Test accuracy: 0.9144893111638955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqY3uxAtmLTE",
        "colab_type": "text"
      },
      "source": [
        "# **CNN Architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTUFLjPiIXJ9",
        "colab_type": "text"
      },
      "source": [
        "## **ConvNet  with 32 filters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vR5STDAmr-o",
        "colab_type": "code",
        "outputId": "0b94f122-578c-4d1e-dfb7-911b0e73f2d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D,Conv1D, MaxPooling2D,MaxPooling1D\n",
        "from keras import backend as K\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform',input_shape=(128,9)))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_3 (Conv1D)            (None, 126, 32)           896       \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 124, 32)           3104      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 124, 32)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 62, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1984)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 50)                99250     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 103,556\n",
            "Trainable params: 103,556\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHH3xNagmsIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils\n",
        "import math\n",
        "from keras import optimizers\n",
        "adam = keras.optimizers.Adam(lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xBKzRBAmsQN",
        "colab_type": "code",
        "outputId": "b09bff90-f336-4d98-de02-2b532bedad2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        }
      },
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "          batch_size=16,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "7352/7352 [==============================] - 6s 755us/step - loss: 0.4242 - acc: 0.8342 - val_loss: 0.4439 - val_acc: 0.8269\n",
            "Epoch 2/20\n",
            "7352/7352 [==============================] - 4s 604us/step - loss: 0.1653 - acc: 0.9329 - val_loss: 0.4324 - val_acc: 0.8785\n",
            "Epoch 3/20\n",
            "7352/7352 [==============================] - 4s 598us/step - loss: 0.1302 - acc: 0.9470 - val_loss: 0.4259 - val_acc: 0.8850\n",
            "Epoch 4/20\n",
            "7352/7352 [==============================] - 4s 601us/step - loss: 0.1190 - acc: 0.9517 - val_loss: 0.4608 - val_acc: 0.8680\n",
            "Epoch 5/20\n",
            "7352/7352 [==============================] - 4s 603us/step - loss: 0.1162 - acc: 0.9520 - val_loss: 0.4690 - val_acc: 0.8860\n",
            "Epoch 6/20\n",
            "7352/7352 [==============================] - 4s 603us/step - loss: 0.1024 - acc: 0.9574 - val_loss: 0.4608 - val_acc: 0.8979\n",
            "Epoch 7/20\n",
            "7352/7352 [==============================] - 4s 598us/step - loss: 0.0995 - acc: 0.9551 - val_loss: 0.5239 - val_acc: 0.8663\n",
            "Epoch 8/20\n",
            "7352/7352 [==============================] - 4s 602us/step - loss: 0.1014 - acc: 0.9554 - val_loss: 0.3797 - val_acc: 0.8928\n",
            "Epoch 9/20\n",
            "7352/7352 [==============================] - 4s 605us/step - loss: 0.0938 - acc: 0.9576 - val_loss: 0.4392 - val_acc: 0.8945\n",
            "Epoch 10/20\n",
            "7352/7352 [==============================] - 4s 604us/step - loss: 0.0829 - acc: 0.9633 - val_loss: 0.5223 - val_acc: 0.8717\n",
            "Epoch 11/20\n",
            "7352/7352 [==============================] - 4s 601us/step - loss: 0.0782 - acc: 0.9631 - val_loss: 0.5173 - val_acc: 0.8850\n",
            "Epoch 12/20\n",
            "7352/7352 [==============================] - 4s 600us/step - loss: 0.0872 - acc: 0.9614 - val_loss: 0.5691 - val_acc: 0.8728\n",
            "Epoch 13/20\n",
            "7352/7352 [==============================] - 4s 612us/step - loss: 0.0818 - acc: 0.9656 - val_loss: 0.5020 - val_acc: 0.8938\n",
            "Epoch 14/20\n",
            "7352/7352 [==============================] - 4s 597us/step - loss: 0.0692 - acc: 0.9668 - val_loss: 0.5374 - val_acc: 0.8595\n",
            "Epoch 15/20\n",
            "7352/7352 [==============================] - 4s 607us/step - loss: 0.0705 - acc: 0.9669 - val_loss: 0.5101 - val_acc: 0.8853\n",
            "Epoch 16/20\n",
            "7352/7352 [==============================] - 4s 611us/step - loss: 0.0737 - acc: 0.9667 - val_loss: 0.6708 - val_acc: 0.8731\n",
            "Epoch 17/20\n",
            "7352/7352 [==============================] - 4s 610us/step - loss: 0.0651 - acc: 0.9697 - val_loss: 0.6450 - val_acc: 0.8819\n",
            "Epoch 18/20\n",
            "7352/7352 [==============================] - 5s 618us/step - loss: 0.0592 - acc: 0.9720 - val_loss: 0.5814 - val_acc: 0.8945\n",
            "Epoch 19/20\n",
            "7352/7352 [==============================] - 5s 614us/step - loss: 0.0614 - acc: 0.9702 - val_loss: 0.5379 - val_acc: 0.8884\n",
            "Epoch 20/20\n",
            "7352/7352 [==============================] - 5s 616us/step - loss: 0.0645 - acc: 0.9732 - val_loss: 0.5706 - val_acc: 0.8867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOcRFA9nmRLp",
        "colab_type": "code",
        "outputId": "6d32600d-8468-472d-ed1e-39057aad8d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D,Conv1D, MaxPooling2D,MaxPooling1D\n",
        "from keras import backend as K\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',input_shape=(128,9)))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "#model.add(Dropout(0.6))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, 126, 32)           896       \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 124, 32)           3104      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 124, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 122, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 61, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1952)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 50)                97650     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 105,060\n",
            "Trainable params: 105,060\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Turtsk_Lmj4S",
        "colab_type": "code",
        "outputId": "f9333f4c-5f94-4b17-efc7-045e7e8253d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import optimizers\n",
        "#sgd = optimizers.SGD(lr=0.01, decay=0.00005, momentum=0.9, nesterov=True)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics = [\"accuracy\"])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "          batch_size=16,\n",
        "          epochs=30,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 6s 843us/step - loss: 0.5358 - acc: 0.7875 - val_loss: 0.5435 - val_acc: 0.7978\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 6s 776us/step - loss: 0.1930 - acc: 0.9302 - val_loss: 0.4397 - val_acc: 0.8704\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 6s 764us/step - loss: 0.1347 - acc: 0.9442 - val_loss: 0.5029 - val_acc: 0.8935\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 6s 767us/step - loss: 0.1293 - acc: 0.9461 - val_loss: 0.4058 - val_acc: 0.8979\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 6s 750us/step - loss: 0.1254 - acc: 0.9505 - val_loss: 0.3995 - val_acc: 0.9023\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 6s 758us/step - loss: 0.1177 - acc: 0.9498 - val_loss: 0.4895 - val_acc: 0.8999\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 6s 753us/step - loss: 0.1107 - acc: 0.9494 - val_loss: 0.5276 - val_acc: 0.8867\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 6s 762us/step - loss: 0.1129 - acc: 0.9516 - val_loss: 0.4485 - val_acc: 0.8996\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 6s 763us/step - loss: 0.1215 - acc: 0.9521 - val_loss: 0.4772 - val_acc: 0.9046\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 6s 759us/step - loss: 0.0961 - acc: 0.9587 - val_loss: 0.4994 - val_acc: 0.8989\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 6s 753us/step - loss: 0.0937 - acc: 0.9601 - val_loss: 0.3806 - val_acc: 0.9084\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 6s 762us/step - loss: 0.0933 - acc: 0.9610 - val_loss: 0.4696 - val_acc: 0.9074\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 6s 748us/step - loss: 0.1043 - acc: 0.9533 - val_loss: 0.6618 - val_acc: 0.8856\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 6s 758us/step - loss: 0.0968 - acc: 0.9574 - val_loss: 0.5947 - val_acc: 0.8968\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 6s 756us/step - loss: 0.0795 - acc: 0.9607 - val_loss: 0.5777 - val_acc: 0.9057\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 6s 750us/step - loss: 0.0783 - acc: 0.9640 - val_loss: 0.7067 - val_acc: 0.8945\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 6s 752us/step - loss: 0.0779 - acc: 0.9645 - val_loss: 0.5904 - val_acc: 0.9036\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 6s 757us/step - loss: 0.0781 - acc: 0.9642 - val_loss: 0.6639 - val_acc: 0.8873\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 6s 762us/step - loss: 0.0703 - acc: 0.9672 - val_loss: 0.6421 - val_acc: 0.9023\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 6s 765us/step - loss: 0.0747 - acc: 0.9682 - val_loss: 0.6779 - val_acc: 0.8999\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 6s 765us/step - loss: 0.0772 - acc: 0.9631 - val_loss: 0.6478 - val_acc: 0.8968\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 6s 764us/step - loss: 0.0666 - acc: 0.9683 - val_loss: 0.6583 - val_acc: 0.9040\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 6s 760us/step - loss: 0.0625 - acc: 0.9705 - val_loss: 0.6910 - val_acc: 0.9016\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 6s 753us/step - loss: 0.0676 - acc: 0.9703 - val_loss: 0.8622 - val_acc: 0.8517\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 6s 761us/step - loss: 0.1222 - acc: 0.9649 - val_loss: 0.6233 - val_acc: 0.8968\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 6s 763us/step - loss: 0.0947 - acc: 0.9717 - val_loss: 0.6609 - val_acc: 0.8968\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 6s 763us/step - loss: 0.0945 - acc: 0.9686 - val_loss: 0.6446 - val_acc: 0.8921\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 6s 761us/step - loss: 0.0989 - acc: 0.9697 - val_loss: 0.5868 - val_acc: 0.9097\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 6s 753us/step - loss: 0.1077 - acc: 0.9667 - val_loss: 0.7268 - val_acc: 0.8890\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 6s 759us/step - loss: 0.0901 - acc: 0.9703 - val_loss: 0.7236 - val_acc: 0.9026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plIYkYK0mkzj",
        "colab_type": "code",
        "outputId": "a094a825-b0b6-4759-e9fc-0946b99a4f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.7236240969682106\n",
            "Test accuracy: 0.9026128266033254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOYCQ3SsrKoP",
        "colab_type": "text"
      },
      "source": [
        "The model is trained and it gives a accuracy of 90%.<br>\n",
        "Now I reduce the number of CONV layers and then the train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBixnro49fLj",
        "colab_type": "code",
        "outputId": "21f51238-7d16-4867-d2c0-2d9715dbd3bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',input_shape=(128,9)))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_8 (Conv1D)            (None, 126, 32)           896       \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 124, 32)           3104      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 124, 32)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 62, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1984)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 50)                99250     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 103,556\n",
            "Trainable params: 103,556\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDyKT50F9mo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRvTyxex9uL9",
        "colab_type": "code",
        "outputId": "c2971308-0ce2-47bf-a314-95e2dc141b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train,Y_train, epochs=30, batch_size=16,validation_data=(X_test, Y_test), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 5s 724us/step - loss: 0.4910 - acc: 0.7986 - val_loss: 0.4949 - val_acc: 0.7991\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 4s 588us/step - loss: 0.1991 - acc: 0.9240 - val_loss: 0.3604 - val_acc: 0.8802\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 4s 576us/step - loss: 0.1443 - acc: 0.9438 - val_loss: 0.3079 - val_acc: 0.8921\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 4s 587us/step - loss: 0.1221 - acc: 0.9498 - val_loss: 0.3357 - val_acc: 0.8914\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 4s 584us/step - loss: 0.1185 - acc: 0.9523 - val_loss: 0.3230 - val_acc: 0.8839\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 4s 582us/step - loss: 0.1064 - acc: 0.9547 - val_loss: 0.5156 - val_acc: 0.8697\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 4s 584us/step - loss: 0.1115 - acc: 0.9528 - val_loss: 0.3729 - val_acc: 0.8901\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 4s 567us/step - loss: 0.1140 - acc: 0.9532 - val_loss: 0.3994 - val_acc: 0.9030\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 4s 570us/step - loss: 0.0999 - acc: 0.9580 - val_loss: 0.3810 - val_acc: 0.8972\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 4s 562us/step - loss: 0.1001 - acc: 0.9566 - val_loss: 0.3100 - val_acc: 0.9006\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 4s 564us/step - loss: 0.0936 - acc: 0.9580 - val_loss: 0.4198 - val_acc: 0.8928\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 4s 566us/step - loss: 0.0979 - acc: 0.9567 - val_loss: 0.3410 - val_acc: 0.9087\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 4s 574us/step - loss: 0.0862 - acc: 0.9612 - val_loss: 0.3686 - val_acc: 0.9019\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 4s 568us/step - loss: 0.0807 - acc: 0.9621 - val_loss: 0.3415 - val_acc: 0.9175\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 4s 572us/step - loss: 0.0832 - acc: 0.9623 - val_loss: 0.3393 - val_acc: 0.9175\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 4s 561us/step - loss: 0.0849 - acc: 0.9637 - val_loss: 0.3193 - val_acc: 0.9209\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 4s 553us/step - loss: 0.0742 - acc: 0.9653 - val_loss: 0.3329 - val_acc: 0.9145\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 4s 578us/step - loss: 0.0655 - acc: 0.9699 - val_loss: 0.3570 - val_acc: 0.9128\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 4s 582us/step - loss: 0.0638 - acc: 0.9737 - val_loss: 0.2970 - val_acc: 0.9128\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 4s 582us/step - loss: 0.0725 - acc: 0.9671 - val_loss: 0.4766 - val_acc: 0.8982\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 4s 570us/step - loss: 0.0661 - acc: 0.9695 - val_loss: 0.3839 - val_acc: 0.9175\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 4s 571us/step - loss: 0.0651 - acc: 0.9731 - val_loss: 0.3482 - val_acc: 0.9125\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 4s 575us/step - loss: 0.0617 - acc: 0.9725 - val_loss: 0.3468 - val_acc: 0.9033\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 4s 571us/step - loss: 0.0644 - acc: 0.9714 - val_loss: 0.3958 - val_acc: 0.9152\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 4s 566us/step - loss: 0.0587 - acc: 0.9752 - val_loss: 0.3946 - val_acc: 0.9155\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 4s 580us/step - loss: 0.0560 - acc: 0.9723 - val_loss: 0.5031 - val_acc: 0.8992\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 4s 582us/step - loss: 0.0530 - acc: 0.9758 - val_loss: 0.4643 - val_acc: 0.8880\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 4s 562us/step - loss: 0.0551 - acc: 0.9735 - val_loss: 0.3533 - val_acc: 0.9209\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 4s 582us/step - loss: 0.0501 - acc: 0.9759 - val_loss: 0.4442 - val_acc: 0.8897\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 4s 576us/step - loss: 0.0744 - acc: 0.9690 - val_loss: 0.3916 - val_acc: 0.9108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5c3cf2b8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzALpmUZ-AQB",
        "colab_type": "code",
        "outputId": "e060e30b-c911-428e-bdd0-6b9b50039d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.3916387325668766\n",
            "Test accuracy: 0.9107567017305734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIkuCeY8rhrK",
        "colab_type": "text"
      },
      "source": [
        "We observe a improvemnet in the accuracy 91%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh3vdqohKbaT",
        "colab_type": "text"
      },
      "source": [
        "# **CNN Architecture 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VNYEk5Lr4xr",
        "colab_type": "text"
      },
      "source": [
        "Here is the paper I refred to (https://www.sciencedirect.com/science/article/pii/S0957417416302056). I made used of a similar architecture of a multi layer ConvNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aT85DUHpWUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJSIq0kOpWnw",
        "colab_type": "code",
        "outputId": "57a72d56-2970-444c-f394-1bfbd741be65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "#Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition, 2016.\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D,Conv1D, MaxPooling2D,MaxPooling1D\n",
        "from keras import backend as K\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=5, activation='relu',input_shape=(128,9)))\n",
        "model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_14 (Conv1D)           (None, 124, 64)           2944      \n",
            "_________________________________________________________________\n",
            "conv1d_15 (Conv1D)           (None, 120, 64)           20544     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 60, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_16 (Conv1D)           (None, 56, 64)            20544     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 56, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 28, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 50)                89650     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 133,988\n",
            "Trainable params: 133,988\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ro98XHppgwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LicsDHLgpls7",
        "colab_type": "code",
        "outputId": "cbb45cc8-dc5c-4bdb-dcc2-d2c83b326ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train,Y_train, epochs=30, batch_size=16,validation_data=(X_test, Y_test), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 11s 2ms/step - loss: 0.3970 - acc: 0.8434 - val_loss: 0.4124 - val_acc: 0.8761\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1575 - acc: 0.9370 - val_loss: 0.3159 - val_acc: 0.9104\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1292 - acc: 0.9487 - val_loss: 0.3791 - val_acc: 0.8853\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1298 - acc: 0.9512 - val_loss: 0.4278 - val_acc: 0.9006\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1215 - acc: 0.9508 - val_loss: 0.4364 - val_acc: 0.8839\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1065 - acc: 0.9543 - val_loss: 0.1832 - val_acc: 0.9274\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0979 - acc: 0.9581 - val_loss: 0.2354 - val_acc: 0.9182\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1460 - acc: 0.9483 - val_loss: 0.4598 - val_acc: 0.9046\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1047 - acc: 0.9553 - val_loss: 0.2637 - val_acc: 0.9257\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0962 - acc: 0.9570 - val_loss: 0.3002 - val_acc: 0.9192\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0992 - acc: 0.9573 - val_loss: 0.2777 - val_acc: 0.9023\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0892 - acc: 0.9612 - val_loss: 0.3305 - val_acc: 0.9148\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0809 - acc: 0.9629 - val_loss: 0.2558 - val_acc: 0.9291\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0794 - acc: 0.9621 - val_loss: 0.3435 - val_acc: 0.9203\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1872 - acc: 0.9486 - val_loss: 0.2962 - val_acc: 0.9260\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0915 - acc: 0.9574 - val_loss: 0.3465 - val_acc: 0.9264\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0780 - acc: 0.9623 - val_loss: 0.4112 - val_acc: 0.9199\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0697 - acc: 0.9674 - val_loss: 0.4075 - val_acc: 0.9189\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0652 - acc: 0.9683 - val_loss: 0.4008 - val_acc: 0.9277\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0668 - acc: 0.9682 - val_loss: 0.3883 - val_acc: 0.9172\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0639 - acc: 0.9659 - val_loss: 0.3554 - val_acc: 0.9182\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0852 - acc: 0.9664 - val_loss: 0.5597 - val_acc: 0.9030\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1752 - acc: 0.9611 - val_loss: 0.6497 - val_acc: 0.9108\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1823 - acc: 0.9619 - val_loss: 0.4066 - val_acc: 0.9240\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1988 - acc: 0.9577 - val_loss: 0.5431 - val_acc: 0.9114\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1389 - acc: 0.9646 - val_loss: 0.4965 - val_acc: 0.9203\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1248 - acc: 0.9689 - val_loss: 0.6321 - val_acc: 0.9118\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1255 - acc: 0.9676 - val_loss: 0.5155 - val_acc: 0.9108\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0800 - acc: 0.9747 - val_loss: 0.4425 - val_acc: 0.9141\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0843 - acc: 0.9714 - val_loss: 0.4692 - val_acc: 0.9270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff5094d73c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAiY64I1pkba",
        "colab_type": "code",
        "outputId": "596aaaca-a71b-46bf-e669-459853b626ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.46918977352065117\n",
            "Test accuracy: 0.9270444519850696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4HnbR_OurTP",
        "colab_type": "text"
      },
      "source": [
        "The model gives a good accuracy of 92.7% and test loss of 0.46 <br>\n",
        "It is observed that a CNN based model performs better than LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSkQq0isa7cJ",
        "colab_type": "text"
      },
      "source": [
        "# **ConvNet with Batch Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Y3zUcA5LbM",
        "colab_type": "code",
        "outputId": "19d255cf-4d61-412b-95d2-5d9821649a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "#Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition, 2016.\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D,Conv1D, MaxPooling2D,MaxPooling1D\n",
        "from keras import backend as K\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=5, activation='relu',input_shape=(128,9)))\n",
        "model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 124, 64)           2944      \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 120, 64)           20544     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 60, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 56, 64)            20544     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 56, 64)            256       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 56, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 28, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                89650     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 134,244\n",
            "Trainable params: 134,116\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QeqedTl6SS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TID19Dl86TIt",
        "colab_type": "code",
        "outputId": "79333a63-9b04-469f-9d88-8459a7ab8b22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train,Y_train, epochs=30, batch_size=batch_size,validation_data=(X_test, Y_test), verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 11s 2ms/step - loss: 0.3970 - acc: 0.8434 - val_loss: 0.4124 - val_acc: 0.8761\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1575 - acc: 0.9370 - val_loss: 0.3159 - val_acc: 0.9104\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1292 - acc: 0.9487 - val_loss: 0.3791 - val_acc: 0.8853\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1298 - acc: 0.9512 - val_loss: 0.4278 - val_acc: 0.9006\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1215 - acc: 0.9508 - val_loss: 0.4364 - val_acc: 0.8839\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1065 - acc: 0.9543 - val_loss: 0.1832 - val_acc: 0.9274\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0979 - acc: 0.9581 - val_loss: 0.2354 - val_acc: 0.9182\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1460 - acc: 0.9483 - val_loss: 0.4598 - val_acc: 0.9046\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1047 - acc: 0.9553 - val_loss: 0.2637 - val_acc: 0.9257\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0962 - acc: 0.9570 - val_loss: 0.3002 - val_acc: 0.9192\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0992 - acc: 0.9573 - val_loss: 0.2777 - val_acc: 0.9023\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0892 - acc: 0.9612 - val_loss: 0.3305 - val_acc: 0.9148\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0809 - acc: 0.9629 - val_loss: 0.2558 - val_acc: 0.9291\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0794 - acc: 0.9621 - val_loss: 0.3435 - val_acc: 0.9203\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1872 - acc: 0.9486 - val_loss: 0.2962 - val_acc: 0.9260\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0915 - acc: 0.9574 - val_loss: 0.3465 - val_acc: 0.9264\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0780 - acc: 0.9623 - val_loss: 0.4112 - val_acc: 0.9199\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0697 - acc: 0.9674 - val_loss: 0.4075 - val_acc: 0.9189\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0652 - acc: 0.9683 - val_loss: 0.4008 - val_acc: 0.9277\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0668 - acc: 0.9682 - val_loss: 0.3883 - val_acc: 0.9172\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0639 - acc: 0.9659 - val_loss: 0.3554 - val_acc: 0.9182\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0852 - acc: 0.9664 - val_loss: 0.5597 - val_acc: 0.9030\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1752 - acc: 0.9611 - val_loss: 0.6497 - val_acc: 0.9108\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1823 - acc: 0.9619 - val_loss: 0.4066 - val_acc: 0.9240\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1988 - acc: 0.9577 - val_loss: 0.5431 - val_acc: 0.9114\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1389 - acc: 0.9646 - val_loss: 0.4965 - val_acc: 0.9203\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1248 - acc: 0.9689 - val_loss: 0.6321 - val_acc: 0.9218\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1255 - acc: 0.9676 - val_loss: 0.5155 - val_acc: 0.9199\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0800 - acc: 0.9747 - val_loss: 0.4425 - val_acc: 0.9288\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 10s 1ms/step - loss: 0.0843 - acc: 0.9714 - val_loss: 0.4692 - val_acc: 0.9292\n",
            "<keras.callbacks.History at 0x7ff5094d73c8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEEoicJiSjyc",
        "colab_type": "code",
        "outputId": "78ded0ad-679b-4fda-e1ad-c1d0e0e20fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:',score[0])\n",
        "print('Test accuracy:',score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.4692240974282106\n",
            "Test accuracy: 0.9292128266033254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tqUs9WGnEPh",
        "colab_type": "text"
      },
      "source": [
        "Here we get a accuracy of 93%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s93PDdbYc8Vz",
        "colab_type": "text"
      },
      "source": [
        "## **Conclusion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXz20TJOdAHx",
        "colab_type": "code",
        "outputId": "21df46d9-7ed5-41cd-9f51-20e5b4f707bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "from prettytable import PrettyTable    \n",
        "x = PrettyTable()\n",
        "x.field_names = [\"Model\",\"Accuracy\"]\n",
        "x.add_row(['1 layer LSTM with 32 units',\"90.1%\"])\n",
        "x.add_row(['1 layer LSTM with 128 units',\"60%\"])\n",
        "x.add_row(['1 layer LSTM with 48 units',\"90.2%\"])\n",
        "x.add_row(['1 layer LSTM with 32 units with 0.3 dropout',\"90.6%\"])\n",
        "x.add_row(['2 layer LSTM with 32 units',\"90%\"])\n",
        "x.add_row(['2 layer LSTM with 64 units',\"91.1%\"])\n",
        "x.add_row(['2 layer LSTM with 128 units',\"90.8%\"])\n",
        "x.add_row(['2 layer LSTM with 128 units with droput rate 0.5',\"91.4%\"])\n",
        "x.add_row(['ConvNet(2 conv layer with 32 filters)',\"88%\"])\n",
        "x.add_row(['ConvNet(3 conv layer with 32 filter)',\"90.8%\"])\n",
        "x.add_row(['Convnet with 64 filter',\"92.6%\"])\n",
        "x.add_row(['Convnet with 64 filter with Batch Normalization',\"93%\"])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+----------+\n",
            "|                      Model                       | Accuracy |\n",
            "+--------------------------------------------------+----------+\n",
            "|            1 layer LSTM with 32 units            |  90.1%   |\n",
            "|           1 layer LSTM with 128 units            |   60%    |\n",
            "|            1 layer LSTM with 48 units            |  90.2%   |\n",
            "|   1 layer LSTM with 32 units with 0.3 dropout    |  90.6%   |\n",
            "|            2 layer LSTM with 32 units            |   90%    |\n",
            "|            2 layer LSTM with 64 units            |  91.1%   |\n",
            "|           2 layer LSTM with 128 units            |  90.8%   |\n",
            "| 2 layer LSTM with 128 units with droput rate 0.5 |  91.4%   |\n",
            "|      ConvNet(2 conv layer with 32 filters)       |   88%    |\n",
            "|       ConvNet(3 conv layer with 32 filter)       |  90.8%   |\n",
            "|              Convnet with 64 filter              |  92.6%   |\n",
            "| Convnet with 64 filter with Batch Normalization  |   93%    |\n",
            "+--------------------------------------------------+----------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-YRDy4cq5PS",
        "colab_type": "text"
      },
      "source": [
        "It is observed that CNN works better than LSTM.<br>\n",
        "I experimented with variuos LSTM model but coudn't improve the accuracy<br>\n",
        "At the end ConvNet with 92.9% ~ 93% accuracy works the best which is close to 94%.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StPdyyQ8q4H-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}